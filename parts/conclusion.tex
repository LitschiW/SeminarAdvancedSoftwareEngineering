\section{Comparison of methods}
\begin{figure}[t]
	\centering
	\captionof{table}{Measureing results of \citet{FasterDiscoveryofFasterSystemConfigurationsSiegmund2017} when comparing the methods of, \AFID(Siegmund), \VAPP(Gou), \WHAT~and projective sampling in combination with CARTs(Sarkar). The \textit{Rank} column is computed using Scott-Knott, bootstrap 95\% confidence, and A12 test.}	
	\label{tab:ConclusionPerformanceOverview}
	\vspace{-.5\baselineskip}
	\includegraphics[page=19, clip=true, trim=2.5cm 13.8cm 6.8cm 3.1cm, width=.9\linewidth]{"Paper/Faster Discovery of Faster System Configurations with Spectral Learning".pdf}
	\vspace{-1\baselineskip}	
\end{figure}
\cref{tab:ConclusionPerformanceOverview} displays the results of an experiment conducted by \citet{FasterDiscoveryofFasterSystemConfigurationsSiegmund2017} to compare different prediction methods. The table shows some characteristic properties of each approach. For example is the standard deviation of \WHAT~only 2.98\%. Having a low standard deviation was one fo the goals of \What. 

Siegmund's approach of \AFID was ranked last on 4 occasions. Its accuracy and standard deviation are the worst in most cases. It mostly ranks lower than \VAPP with the same sample size (Guo(PW)). \WHAT~is the oldest of the presented approaches and its low ranking can be seen as a demonstration on how prediction algorithms evolved over time.

Sarkar's approach of using cost-efficient sampling in combination with CARTs ranked best in four out of the six cases. In the remaining twp cases it had still an acceptable accuracy. But this consistent high accuracy comes with the cost of using larger samples then other methods. In the case of SQLite, the sample was 15 times larger than the sample of the next best approach \WHAT. 


In conclusion 


If time and resources are available or a program is sufficiently small, \textit{brute force} can be applied to get perfect results.\textsl{} 




\FloatBarrier
\section{Further and Future Work}



\section{Conclusion}