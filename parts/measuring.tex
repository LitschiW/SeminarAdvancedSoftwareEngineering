\section{Measuring and Predicting the Performance of Highly Configurable Systems}

With such a large amount of customization options a 

\subsection{Automated Feature Interaction Detection}


\let\oldPi\Pi
\renewcommand{\Pi}{\ensuremath{\mathrm{\oldPi}}}
\let\oldRef\ref
\renewcommand{\ref}[1]{(\oldRef{#1})}

Automated feature detection is the most straight forward approach to predicting the performance of a highly configurable system.
It was developed by \citet{AutomatedFeatureDetectionSiegmund2012}. Unlike other methods it does not depend on machine learning but rather tires to identify the performance impact of each feature and each features interactions. This method reaches a precision of 95\% in predicting a systems performance \cite{AutomatedFeatureDetectionSiegmund2012}. 
\subsubsection{Formulars}
The composition of using two (or more) units/features is denoted by $\cdot$. The interaction of two features is denoted by $a\#b$. By combining both we get a feature interaction:
\begin{equation}
 a \times b = a\#b \cdot a \cdot b
\end{equation} 
This equation expresses, that when using both $a$ and $b$ we also need to consider their interaction $a\cdot b$.\\
Further Sigmund defines a performance function $\Pi$ that is used to represent the performance value of a configuration:
\begin{align}
\Pi(a \cdot b) &= \Pi(a) + \Pi(b)\label{eq:featureInteraction_SimplePerformance}\\
\Pi(a\#b) &= \Pi(a \times b) - (\Pi(a) + \Pi(b))\\
\Pi(a \times b) &=  \Pi(a\#b) + (\Pi(a) + \Pi(b))\label{eq:featureInteraction_InteractionPerformances}
\end{align}
Following that the performance of a program $P = a \times b \times c$ can be written down as
\begin{equation}\label{eq:featureInteraction_ProgrammPerformance}
\Pi(P) = \Pi(a) +  \Pi(b) +  \Pi(c) +  \Pi(a\#b) +  \Pi(a\#c) +  \Pi(b\#c) +  \Pi(a\#b\#c). 
\end{equation}
The Problem with the equations \ref{eq:featureInteraction_SimplePerformance}-\ref{eq:featureInteraction_ProgrammPerformance} is that they assumes that we can measure the performance of a feature in isolation. This is in general not possible \cite{AutomatedFeatureDetectionSiegmund2012}. Also we are still in the space of $\mathcal{O}(2^n)$ of possible configurations that we need to measure.  
To reduce this Sigmund et al. uses a \textit{delta}. 
\begin{equation}
\begin{split}
\Delta a_C &= \Pi(C\times a) - \Pi(C)\\
&=\Pi(a\# C) + \Pi(a)
\end{split}
\end{equation}
Where $C$ is a base configuration. This formula describes how the performance influence ($\Delta$) of $a$ in a configuration $C$ can be calculated. Its either the performance difference between using $C$ with and without $a$, or the performance influence of $a$ itself plus the influence of the interaction between $C$ and $a$.
For a general approach Automatic Feature Interaction Detection (AFID) looks at
\begin{minipage}{\textwidth}
\begin{equation}
	\Delta a_{min} = \Pi(a \times min(a)) - \Pi(min(a))
\end{equation}
\begin{center}
	and
\end{center}
\begin{equation}
	\Delta a_{max} = \Pi(a \times max(a)) - \Pi(max(a))
\end{equation}
\end{minipage}\\[0.3cm]
 Where $min(a)$ is a valid minimal configuration not containing $a$ but to which $a$ can be added to create another valid configuration. $max(a)$ is a valid maximal configuration not containing $a$ but to which $a$ can be added to create another valid configuration.\\
 \subsubsection[Automated detection of feature interaction]{\textnormal{For} automated detection of feature interaction} 
one first needs to define when a feature is interacting. For this \citet{AutomatedFeatureDetectionSiegmund2012} use the definition of 
 \begin{equation}
 a \text{ interacts} \Leftrightarrow \exists C,D | C \neq D  \land	 \Delta a_C \neq \Delta a_D .
 \end{equation}
 $C~=~min(a)$ and $D~=~max(a)$ are chosen to find interacting features and to reduce the search space for $C$ or $D$ from $\mathcal{O}(2^n)$ to $\mathcal{O}(n)$. By measuring $\Delta a_{min(a)}=\Delta a_C$ and $\Delta a_{max(a)}=\Delta a_D$ for each feature some first information about their behavior can be obtained. If both values for a feature $a$ are similar it does not interact with the features of $max(a)\backslash min(a)$. Otherwise $a$ is marked as interacting. In both cases it can still interact with the features of $min(a)$. In total 4 measurements per feature are required ($\Pi(a \times min(a))$, $\Pi(min(a))$, $\Pi(a\times max(a))$, $\Pi(max(a))$).\\
 Since most of the interacting features are known by now one can look for the groups of features whose interaction does have an influence on performance. Again the problem arises that there is an exponential number of possible combinations. Three heuristics are used to simplify the finding of these groups.
 
 \newcommand{\oitem}[2]{{\item[{\parbox[t][0pt][t]{\leftmargin}{\raggedleft #1}}] {\parbox[t]{\textwidth-\leftmargin}{#2}}}}
 \begin{itemize}[leftmargin=4cm]
 	\setlength\itemsep{1em}
 	\oitem{Pair-Wise~Heuristik (PW):}{ Most groups of interacting features appear in the size of two\cite{AutomatedFeatureDetectionSiegmund2012,AnalysisOfTheVariabilityInFortyPreprocessor_BasedSPLLiebig}. So it makes sense to look for pair interaction first.}
 	\oitem{Composition of Higher-Order Interactions Heuristic (HO):}{
 		\citet{AutomatedFeatureDetectionSiegmund2012} only look at higher order interactions of the rank of three. These can be relatively easily found by looking hat the results of the PW-Heuristik. Three features that interact pair-wise	are likely to interact in a 3rd order interaction. For example, looking at features $a$, $b$ and $c$, $\{a\#b, b\#c, a\#c\}$ all have to be non zero. Higher order interactions are not considered to prevent too many measurements.
 	}
 	\oitem{Hot-Spot Features (HS):}{
 		Based on \cite{FeatureCohesioninSPL, CanWeAvoidHighCoupling?} \citet{AutomatedFeatureDetectionSiegmund2012} assume that hot spot features exist. \inlineQuote{[...] There are usually a few features that interact with	many features and there are many features that interact only with few features.}, these features are the hot spot features. The actual detection will happen in the next step .Interactions with an order higher than three are also ignored here. 
 	}
 \end{itemize}

Using a SAT-Solver an implication graph as seen in \TODOX{graph einf√ºgen} is generated. Each implication chain in this tree should have an interacting feature.  
